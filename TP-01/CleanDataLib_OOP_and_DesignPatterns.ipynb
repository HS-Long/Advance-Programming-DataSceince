{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP-1: CleaningData - Applying OOP and Design Patterns\n",
    "\n",
    "Each exercise builds upon the previous one - so by the end, we will have a complete CSV cleaning data using OOP, decorators, and patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import libraries and load the sample dataset. Run this cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0f05fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>city</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>29.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Eva</td>\n",
       "      <td>27.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name   age  height_cm  weight_kg         city  score\n",
       "0   1    Alice  29.0      165.0       68.0     New York   85.0\n",
       "1   2      Bob   NaN      172.0        NaN  Los Angeles   90.0\n",
       "2   3  Charlie  35.0      168.0       72.0      Chicago    NaN\n",
       "3   4    David   NaN        NaN       80.0      Houston   75.0\n",
       "4   5      Eva  27.0      160.0       55.0     New York   88.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path(r'/Users/visal/Documents/ITC-AMS/Semester I 2025-2026/Advance Programming for Data Science/TP/Week-1/Code/sample_data.csv')\n",
    "print('Dataset exists:', DATA_PATH.exists())\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1d20d",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercise 1 - `CSVReader` class (OOP foundation)\n",
    "\n",
    "**Goal:** Build a `CSVReader` that encapsulates reading and previewing a CSV file.\n",
    "\n",
    "### Starter code\n",
    "Fill in the `TODO` parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3337c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class CSVReader:\n",
    "    def __init__(self, file_path: str):\n",
    "        # TODO: store the path and initialize internal state\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def read(self) -> pd.DataFrame:\n",
    "        \"\"\"Read CSV into a pandas DataFrame and store it in self.data\"\"\"\n",
    "        # TODO: implement reading\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data\n",
    "\n",
    "    def preview(self, n=5):\n",
    "        # TODO: implement preview\n",
    "        if self.data is None:\n",
    "            print('No data loaded. Call .read() first.')\n",
    "        else:\n",
    "            display(self.data.head(n))\n",
    "\n",
    "# Your turn: instantiate and call\n",
    "reader = CSVReader(str(DATA_PATH))\n",
    "df = reader.read()\n",
    "reader.preview(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f51651",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercise 2 - Strategy Pattern for Missing Value Handling\n",
    "\n",
    "**Goal:** Implement interchangeable missing-value strategies and a `DataCleaner` that uses them.\n",
    "\n",
    "### Starter code\n",
    "Fill the `TODO` parts. Instructor solutions are commented below each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "class MissingValueStrategy(ABC):\n",
    "    @abstractmethod\n",
    "    def handle(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "class DropMissing(MissingValueStrategy):\n",
    "    def handle(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # TODO: drop rows with any missing values\n",
    "        return df.dropna()\n",
    "\n",
    "class FillMean(MissingValueStrategy):\n",
    "    def handle(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # TODO: fill numeric NaNs with column mean\n",
    "        return df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "class FillMode(MissingValueStrategy):\n",
    "    def handle(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # TODO: fill NaNs with mode for each column (if mode exists)\n",
    "        df_copy = df.copy()\n",
    "        for col in df_copy.columns:\n",
    "            try:\n",
    "                mode_val = df_copy[col].mode(dropna=True)\n",
    "                if not mode_val.empty:\n",
    "                    df_copy[col].fillna(mode_val.iloc[0], inplace=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return df_copy\n",
    "\n",
    "class DataCleaner:\n",
    "    def __init__(self, strategy: MissingValueStrategy):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def clean(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return self.strategy.handle(df)\n",
    "\n",
    "# Your turn: test different strategies\n",
    "cleaner_mean = DataCleaner(FillMean())\n",
    "df_mean = cleaner_mean.clean(df)\n",
    "df_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a7dcd",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercise 3 - Decorators for Logging and Timing\n",
    "\n",
    "**Goal:** Implement simple decorators to log actions and execution time and apply them to methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82834696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def log_action(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"[LOG] Starting {func.__name__}()\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"[LOG] Finished {func.__name__}()\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def log_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        duration = time.time() - start\n",
    "        print(f\"[TIME] {func.__name__} executed in {duration:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Apply to CSVReader.read (example)\n",
    "class CSVReaderWithLogging(CSVReader):\n",
    "    @log_time\n",
    "    @log_action\n",
    "    def read(self):\n",
    "        return super().read()\n",
    "\n",
    "reader_logged = CSVReaderWithLogging(str(DATA_PATH))\n",
    "df_logged = reader_logged.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a0f84",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercise 4 - Factory Pattern for Transformations\n",
    "\n",
    "### Goal:\n",
    "Provide a way to obtain transformation objects via a factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataTransform(ABC):\n",
    "    @abstractmethod\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "class NormalizeColumns(DataTransform):\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df2 = df.copy()\n",
    "        df2.columns = [c.strip().lower().replace(' ', '_') for c in df2.columns]\n",
    "        return df2\n",
    "\n",
    "class RemoveDuplicates(DataTransform):\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.drop_duplicates()\n",
    "\n",
    "class StandardizeText(DataTransform):\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df2 = df.copy()\n",
    "        for col in df2.select_dtypes(include='object').columns:\n",
    "            df2[col] = df2[col].str.strip().str.lower()\n",
    "        return df2\n",
    "\n",
    "class TransformFactory:\n",
    "    def get_transform(self, name: str) -> DataTransform:\n",
    "        name = name.lower()\n",
    "        if name == 'normalize':\n",
    "            return NormalizeColumns()\n",
    "        elif name == 'remove_duplicates':\n",
    "            return RemoveDuplicates()\n",
    "        elif name == 'standardize':\n",
    "            return StandardizeText()\n",
    "        else:\n",
    "            raise ValueError(f'Unknown transform: {name}')\n",
    "\n",
    "# Test factory\n",
    "factory = TransformFactory()\n",
    "t_norm = factory.get_transform('normalize')\n",
    "df_norm = t_norm.apply(df)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24596347",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercise 5 - Template Method: Full Pipeline\n",
    "\n",
    "### Goal: \n",
    "Combine previous components into a pipeline class that defines the workflow skeleton and allows specialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline(ABC):\n",
    "    def run(self):\n",
    "        df = self.load()\n",
    "        df = self.clean(df)\n",
    "        df = self.transform(df)\n",
    "        self.save(df)\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def clean(self, df):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, df):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save(self, df):\n",
    "        pass\n",
    "\n",
    "class CSVDataPipeline(DataPipeline):\n",
    "    def __init__(self, input_path: str, output_path: str):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.reader = CSVReaderWithLogging(input_path)\n",
    "        self.cleaner = DataCleaner(FillMean())\n",
    "        self.factory = TransformFactory()\n",
    "\n",
    "    def load(self):\n",
    "        return self.reader.read()\n",
    "\n",
    "    def clean(self, df):\n",
    "        return self.cleaner.clean(df)\n",
    "\n",
    "    def transform(self, df):\n",
    "        # apply normalization and standardization\n",
    "        df = self.factory.get_transform('normalize').apply(df)\n",
    "        df = self.factory.get_transform('standardize').apply(df)\n",
    "        df = self.factory.get_transform('remove_duplicates').apply(df)\n",
    "        return df\n",
    "\n",
    "    def save(self, df):\n",
    "        df.to_csv(self.output_path, index=False)\n",
    "        print(f'Saved cleaned data to {self.output_path}')\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline = CSVDataPipeline(str(DATA_PATH), 'data/cleaned_sample.csv')\n",
    "pipeline.run()\n",
    "pd.read_csv('data/cleaned_sample.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
